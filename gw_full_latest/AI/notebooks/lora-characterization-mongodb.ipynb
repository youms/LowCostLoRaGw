{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1: Install and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Python 3.7\n",
    "#import subprocess\n",
    "#import sys\n",
    "\n",
    "#packages = ['seaborn', 'plotly', 'kaleido']\n",
    "#for package in packages:\n",
    "#    try:\n",
    "#        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "#    except:\n",
    "#        print(f\"Could not install {package}, continuing without it\")\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator as loc\n",
    "import matplotlib as mpl\n",
    "# mpl.rcParams['figure.dpi'] = 100\n",
    "# mpl.rcParams['font.size'] = 12\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"whitegrid\")\n",
    "except ImportError:\n",
    "    print(\"Seaborn not available, using matplotlib only\")\n",
    "    sns = None\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "# plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple MongoDB-only Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def simple_mongodb_query():\n",
    "    \"\"\"\n",
    "    Simple MongoDB query matching your PHP script exactly\n",
    "    \"\"\"\n",
    "    import pymongo\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Connect (equivalent to new MongoDB\\Driver\\Manager)\n",
    "    client = pymongo.MongoClient(\"mongodb://localhost:27017\")\n",
    "    \n",
    "    # Query (equivalent to new MongoDB\\Driver\\Query with sort)\n",
    "    collection = client.messages.ReceivedData\n",
    "    cursor = collection.find({}).sort(\"time\", 1)\n",
    "    \n",
    "    # Process results (equivalent to PHP IteratorIterator loop)\n",
    "    rows = []\n",
    "    for doc in cursor:\n",
    "        # Handle time conversion (equivalent to gmdate and toDateTime)\n",
    "        if 'time' in doc and hasattr(doc['time'], 'toDateTime'):\n",
    "            time_str = doc['time'].toDateTime().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        else:\n",
    "            time_str = str(doc.get('time', ''))\n",
    "        \n",
    "        # Build row (equivalent to PHP echo with semicolons)\n",
    "        rows.append([\n",
    "            doc.get('type', ''),\n",
    "            doc.get('gateway_eui', ''),\n",
    "            doc.get('node_eui', ''),\n",
    "            doc.get('snr', ''),\n",
    "            doc.get('rssi', ''),\n",
    "            doc.get('len', ''),\n",
    "            doc.get('cr', ''),\n",
    "            doc.get('datarate', ''),\n",
    "            time_str,\n",
    "            doc.get('data', '')\n",
    "        ])\n",
    "    \n",
    "    # Create DataFrame with same column names as PHP output\n",
    "    columns = ['type', 'gateway_eui', 'node_eui', 'snr', 'rssi', 'len', 'cr', 'datarate', 'time', 'data']\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    \n",
    "    client.close()\n",
    "    return df\n",
    "\n",
    "# Use the simple version\n",
    "df = simple_mongodb_query()\n",
    "print(f\"âœ… Loaded {len(df)} rows from MongoDB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Res Plot Export Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot_locally(fig, filename):\n",
    "    \"\"\"\n",
    "    Saves a matplotlib figure to the plots directory.\n",
    "    Args:\n",
    "        fig (matplotlib.figure.Figure): The figure object to save.\n",
    "        filename (str): The name of the file (e.g., \"my_plot.png\").\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create plots directory if it doesn't exist\n",
    "        plots_dir = \"plots\"\n",
    "        os.makedirs(plots_dir, exist_ok=True)\n",
    "        \n",
    "        # Full path for the file\n",
    "        filepath = os.path.join(plots_dir, filename)\n",
    "        \n",
    "        # Save the plot\n",
    "        fig.savefig(filepath, dpi=600, format='png', bbox_inches='tight')\n",
    "        print(f\"âœ… Plot saved to: {filepath}\")\n",
    "        \n",
    "        # Optional: Also save as PDF\n",
    "        pdf_filename = filename.replace('.png', '.pdf')\n",
    "        pdf_filepath = os.path.join(plots_dir, pdf_filename)\n",
    "        fig.savefig(pdf_filepath, dpi=600, format='pdf', bbox_inches='tight')\n",
    "        print(f\"âœ… PDF version saved to: {pdf_filepath}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error saving plot: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell: Data Inspection and Column Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# DATA PREPROCESSING\n",
    "# ===========================\n",
    "\n",
    "#```python\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_lora_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess LoRa characterization data with fixed alignment\n",
    "    \"\"\"\n",
    "    # First fix the column alignment\n",
    "    #df = fix_csv_alignment(df)\n",
    "\n",
    "    print(\"\\nðŸ”„ Processing corrected data...\")\n",
    "\n",
    "    # Convert timestamp - now 'time' has the correct datetime values\n",
    "    try:\n",
    "        df['timestamp'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "        valid_timestamps = df['timestamp'].notna().sum()\n",
    "        print(f\"âœ… Successfully parsed {valid_timestamps} timestamps\")\n",
    "        if valid_timestamps > 0:\n",
    "            print(f\"ðŸ“… Time range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Timestamp parsing error: {e}\")\n",
    "        df['timestamp'] = pd.NaT\n",
    "\n",
    "    # Extract SF and BW from datarate - now 'datarate' has correct values like 'SF7BW125'\n",
    "    if 'datarate' in df.columns:\n",
    "        df['sf'] = df['datarate'].str.extract(r'SF(\\d+)', expand=False)\n",
    "        df['bw'] = df['datarate'].str.extract(r'BW(\\d+)', expand=False)\n",
    "\n",
    "        # Handle missing BW values (some might just be SF7BW125 without explicit BW)\n",
    "        df['bw'] = df['bw'].fillna(125)  # Default to 125 if not specified\n",
    "\n",
    "        # Convert SF, BW, and len to integers\n",
    "        df['sf'] = df['sf'].astype('Int64') # Use Int64 to handle potential NaNs\n",
    "        df['bw'] = df['bw'].astype('Int64')\n",
    "        df['len'] = df['len'].astype('Int64')\n",
    "\n",
    "\n",
    "        print(f\"âœ… Extracted SF values: {sorted(df['sf'].dropna().unique())}\")\n",
    "        print(f\"âœ… Extracted BW values: {sorted(df['bw'].dropna().unique())}\")\n",
    "    else:\n",
    "        print(\"âŒ 'datarate' column not found\")\n",
    "        return df\n",
    "\n",
    "    # Convert numeric columns - now they should have correct numeric values\n",
    "    numeric_cols = ['rssi', 'snr', 'node_eui'] # Exclude 'len' as it's already converted to Int64\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            valid_count = df[col].notna().sum()\n",
    "            print(f\"âœ… Converted {col}: {valid_count} valid values\")\n",
    "            if valid_count > 0:\n",
    "                print(f\"   Range: {df[col].min()} to {df[col].max()}\")\n",
    "        else:\n",
    "            print(f\"âŒ Column '{col}' not found\")\n",
    "\n",
    "    # Create configuration identifier - now using integer values\n",
    "    if all(col in df.columns for col in ['sf', 'bw', 'len']):\n",
    "        df['config'] = (df['sf'].astype(str) + '_BW' +\n",
    "                       df['bw'].astype(str) + '_' +\n",
    "                       df['len'].astype(str) + 'B')\n",
    "\n",
    "\n",
    "        # Create SF category\n",
    "        # Ensure mapping handles potential None/NaN values from Int64 conversion if necessary\n",
    "        df['sf_category'] = df['sf'].map({7: 'MIN-SF7', 9: 'MEAN-SF9', 12: 'MAX-SF12'})\n",
    "\n",
    "\n",
    "        unique_configs = df['config'].nunique()\n",
    "        print(f\"âœ… Created {unique_configs} unique configurations\")\n",
    "        print(f\"ðŸ“‹ Configurations: {sorted(df['config'].unique())}\")\n",
    "\n",
    "    # Add time-based features\n",
    "    if 'timestamp' in df.columns and df['timestamp'].notna().any():\n",
    "        df['time_minutes'] = (df['timestamp'] - df['timestamp'].min()).dt.total_seconds() / 60\n",
    "        # Calculate time difference in seconds between consecutive rows\n",
    "        df['time_diff_seconds'] = df['timestamp'].diff().dt.total_seconds()\n",
    "        # The first row will have a NaN time difference, you might want to fill this or handle it\n",
    "        df['time_diff_seconds'] = df['time_diff_seconds'].fillna(0) # Fill NaN with 0 for the first row\n",
    "\n",
    "        duration = df['time_minutes'].max()\n",
    "        print(f\"âœ… Total experiment duration: {duration:.1f} minutes\")\n",
    "        print(f\"âœ… Added 'time_diff_seconds' column.\")\n",
    "\n",
    "\n",
    "    # Remove rows with missing critical data\n",
    "    initial_rows = len(df)\n",
    "    critical_cols = ['sf', 'rssi', 'snr', 'len']\n",
    "    df = df.dropna(subset=critical_cols)\n",
    "    final_rows = len(df)\n",
    "\n",
    "    if initial_rows != final_rows:\n",
    "        print(f\"âš ï¸ Removed {initial_rows - final_rows} rows with missing critical data\")\n",
    "\n",
    "    print(f\"\\nðŸ“Š Final dataset: {final_rows} rows, {len(df.columns)} columns\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the corrected preprocessing\n",
    "print(\"ðŸš€ Starting corrected data preprocessing...\")\n",
    "df = preprocess_lora_data(df)\n",
    "\n",
    "# Display corrected dataset info\n",
    "if len(df) > 0:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸ“Š CORRECTED DATASET OVERVIEW\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total packets received: {len(df)}\")\n",
    "    if 'timestamp' in df.columns and df['timestamp'].notna().any():\n",
    "        print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "    if 'config' in df.columns:\n",
    "        print(f\"Configurations tested: {df['config'].nunique()}\")\n",
    "        print(f\"SF values: {sorted(df['sf'].dropna().unique())}\")\n",
    "        print(f\"BW values: {sorted(df['bw'].dropna().unique())}\")\n",
    "        print(f\"Payload sizes: {sorted(df['len'].dropna().unique())} bytes\")\n",
    "    if 'rssi' in df.columns:\n",
    "        print(f\"RSSI range: {df['rssi'].min()} to {df['rssi'].max()} dBm\")\n",
    "    if 'snr' in df.columns:\n",
    "        print(f\"SNR range: {df['snr'].min()} to {df['snr'].max()} dB\")\n",
    "\n",
    "\n",
    "    # Show sample of corrected data including the new time_diff_seconds column\n",
    "    print(f\"\\nðŸ“‹ Sample of corrected data:\")\n",
    "    display_cols = ['gateway_eui', 'node_eui', 'snr', 'rssi', 'len', 'datarate', 'time', 'time_diff_seconds', 'config']\n",
    "    available_cols = [col for col in display_cols if col in df.columns]\n",
    "    print(df[available_cols].head(3))\n",
    "else:\n",
    "    print(\"âŒ No valid data after preprocessing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Delete any rows after the last occurence of MAX-SF12-BW125-T80-END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Find the last occurrence of the row with data MAX-SF12-BW125-T20-END and delete the rows after it\n",
    "\n",
    "# Define the specific string to search for\n",
    "end_marker = \"MAX-SF12-BW125-T80-END\" # Based on your request\n",
    "\n",
    "# Find the index of the last occurrence of the end_marker in the 'data' column\n",
    "# We search from the end of the DataFrame\n",
    "last_end_index = df[df['data'].astype(str).str.contains(end_marker, na=False)].index.max()\n",
    "\n",
    "# Check if the marker was found\n",
    "if pd.isna(last_end_index):\n",
    "    print(f\"\\nâš ï¸ Marker '{end_marker}' not found in the 'data' column.\")\n",
    "    print(\"No rows will be deleted based on this marker.\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Last occurrence of marker '{end_marker}' found at index: {last_end_index}\")\n",
    "\n",
    "    # Calculate the number of rows to keep (up to and including the last end_marker)\n",
    "    rows_to_keep = last_end_index + 1\n",
    "\n",
    "    # Delete rows after the last occurrence\n",
    "    initial_rows = len(df)\n",
    "    df = df.iloc[:rows_to_keep]\n",
    "    final_rows = len(df)\n",
    "\n",
    "    deleted_rows_count = initial_rows - final_rows\n",
    "\n",
    "    if deleted_rows_count > 0:\n",
    "        print(f\"ðŸ—‘ï¸ Deleted {deleted_rows_count} rows after index {last_end_index}.\")\n",
    "    else:\n",
    "        print(\"âž¡ï¸ No rows were deleted after the last occurrence of the marker.\")\n",
    "\n",
    "# Display the updated DataFrame information\n",
    "print(f\"\\nðŸ“Š Final dataset size after potential deletion: {len(df)} rows\")\n",
    "\n",
    "# Display the last few rows to confirm deletion\n",
    "print(\"\\nðŸ“‹ Last few rows of the DataFrame after deletion:\")\n",
    "if len(df) > 0:\n",
    "    display(df.tail())\n",
    "else:\n",
    "    print(\"âŒ DataFrame is empty after processing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Delete rows not within a pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: Now delete any row that is not within a pair\n",
    "\n",
    "# Create a new DataFrame to store rows that are within a pair\n",
    "df_cleaned = pd.DataFrame()\n",
    "\n",
    "# Initialize a flag to track if we are currently inside a pair\n",
    "is_inside_pair = False\n",
    "\n",
    "# Find the column containing the string markers.\n",
    "# Assuming the markers \"START\" and \"END\" would appear in the 'data' column\n",
    "marker_column = 'data' # Adjust this if needed based on your data\n",
    "\n",
    "# Iterate through the original preprocessed DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Check if the marker column exists and the value is a string\n",
    "    if marker_column in row and isinstance(row[marker_column], str):\n",
    "        # Check for the START marker\n",
    "        if 'START' in row[marker_column]:\n",
    "            is_inside_pair = True\n",
    "            # Optionally, include the START row in the cleaned data\n",
    "            # df_cleaned = pd.concat([df_cleaned, pd.DataFrame([row])], ignore_index=True)\n",
    "        # Check for the END marker\n",
    "        elif 'END' in row[marker_column]:\n",
    "            # Optionally, include the END row in the cleaned data\n",
    "            # df_cleaned = pd.concat([df_cleaned, pd.DataFrame([row])], ignore_index=True)\n",
    "            is_inside_pair = False # The pair has ended\n",
    "        # If we are inside a pair and the row is not a marker, add it\n",
    "        elif is_inside_pair:\n",
    "            df_cleaned = pd.concat([df_cleaned, pd.DataFrame([row])], ignore_index=True)\n",
    "    # If we are inside a pair and the row is not a marker (e.g., data row), add it\n",
    "    elif is_inside_pair:\n",
    "         df_cleaned = pd.concat([df_cleaned, pd.DataFrame([row])], ignore_index=True)\n",
    "\n",
    "print(f\"\\nInitial number of rows: {len(df)}\")\n",
    "print(f\"Number of rows after removing those outside pairs: {len(df_cleaned)}\")\n",
    "\n",
    "# Update the main DataFrame reference if needed\n",
    "df = df_cleaned\n",
    "\n",
    "# Display the first few rows of the cleaned dataframe\n",
    "print(\"\\nðŸ“‹ Sample of data after removing rows outside pairs:\")\n",
    "if len(df) > 0:\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"âŒ No rows remaining after cleaning based on pairs.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Delete rows that contain START or END to get a clean df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: delete any row that indicates the markers for a pair. we are left with clean data\n",
    "\n",
    "# Find rows that contain either 'START' or 'END' in the marker column\n",
    "rows_to_drop = df[\n",
    "    (df[marker_column].astype(str).str.contains('START', na=False)) |\n",
    "    (df[marker_column].astype(str).str.contains('END', na=False))\n",
    "].index\n",
    "\n",
    "print(f\"\\nNumber of rows identified as markers (START/END): {len(rows_to_drop)}\")\n",
    "\n",
    "# Drop these rows from the DataFrame\n",
    "df_cleaned_no_markers = df.drop(rows_to_drop)\n",
    "\n",
    "print(f\"Initial number of rows in df: {len(df)}\")\n",
    "print(f\"Number of rows after removing marker rows: {len(df_cleaned_no_markers)}\")\n",
    "\n",
    "# Update the main DataFrame reference\n",
    "df = df_cleaned_no_markers\n",
    "\n",
    "# Display the first few rows of the cleaned dataframe (without marker rows)\n",
    "print(\"\\nðŸ“‹ Sample of data after removing marker rows:\")\n",
    "if len(df) > 0:\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"âŒ No rows remaining after removing marker rows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Display the cleaned data frame above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, the `df` variable contains the data with rows outside pairs and marker rows removed.\n",
    "# You can proceed with further analysis using this `df`.\n",
    "\n",
    "# Example: Display info about the final cleaned dataset\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ“Š FINAL CLEANED DATASET OVERVIEW (WITHOUT MARKERS)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total data packets within pairs: {len(df)}\")\n",
    "\n",
    "if len(df) > 0:\n",
    "    if 'timestamp' in df.columns and df['timestamp'].notna().any():\n",
    "        print(f\"Data timestamp range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "    if 'config' in df.columns:\n",
    "        print(f\"Configurations present: {sorted(df['config'].unique())}\")\n",
    "    if 'rssi' in df.columns:\n",
    "        print(f\"RSSI range: {df['rssi'].min()} to {df['rssi'].max()} dBm\")\n",
    "    if 'snr' in df.columns:\n",
    "        print(f\"SNR range: {df['snr'].min()} to {df['snr'].max()} dB\")\n",
    "    if 'len' in df.columns:\n",
    "        print(f\"Payload sizes: {sorted(df['len'].unique())} bytes\")\n",
    "\n",
    "    print(\"\\nðŸ“‹ Sample of final cleaned data:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"âŒ The final DataFrame is empty after cleaning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data is now ready for analysis. Run all cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4: PDR Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# PACKET DELIVERY RATE ANALYSIS\n",
    "# ===========================\n",
    "\n",
    "def calculate_pdr_statistics(df):\n",
    "    \"\"\"\n",
    "    Calculate PDR and related statistics for each configuration\n",
    "    \"\"\"\n",
    "    expected_packets = 200  # As specified in your experiment setup\n",
    "                             # For short tests you can analyse all cycles together. Input the expected packets for all cycles and plot df\n",
    "\n",
    "    stats = df.groupby(['sf', 'bw', 'len']).agg({\n",
    "        'rssi': ['mean', 'std', 'min', 'max'],\n",
    "        'snr': ['mean', 'std', 'min', 'max'],\n",
    "        'timestamp': ['count', 'min', 'max']\n",
    "    }).round(2)\n",
    "\n",
    "    # Flatten column names\n",
    "    stats.columns = ['_'.join(col).strip() for col in stats.columns.values]\n",
    "\n",
    "    # Calculate PDR\n",
    "    stats['packets_received'] = stats['timestamp_count']\n",
    "    stats['expected_packets'] = expected_packets\n",
    "    stats['pdr_percent'] = (stats['packets_received'] / expected_packets * 100).round(1)\n",
    "    stats['packet_loss_percent'] = (100 - stats['pdr_percent']).round(1)\n",
    "\n",
    "    # Calculate duration\n",
    "    stats['duration_minutes'] = ((stats['timestamp_max'] - stats['timestamp_min']).dt.total_seconds() / 60).round(1)\n",
    "\n",
    "    # Reset index for easier plotting\n",
    "    stats = stats.reset_index()\n",
    "    stats['config_name'] = (stats['sf'].astype(str) + '_BW' +\n",
    "                           stats['bw'].astype(str) + '_' +\n",
    "                           stats['len'].astype(str) + 'B')\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Calculate statistics\n",
    "pdr_stats = calculate_pdr_statistics(df) # selected_cycle_df is for short tests. Use df if you have only 1 full cycle accross all configs\n",
    "print(\"PDR Statistics Summary\")\n",
    "print(pdr_stats[['sf', 'bw', 'len', 'packets_received', 'pdr_percent', 'rssi_mean', 'snr_mean']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 5: Basic Plots (Matplotlib only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDR Analysis Plot\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# PDR bar chart\n",
    "ax1.bar(range(len(pdr_stats)), pdr_stats['pdr_percent'], \n",
    "        color=['green' if sf==7 else 'blue' if sf==9 else 'red' for sf in pdr_stats['sf']])\n",
    "ax1.set_title('Packet Delivery Rate by Configuration')\n",
    "ax1.set_xlabel('Configuration Index')\n",
    "ax1.set_ylabel('PDR (%)')\n",
    "# ax1.axhline(y=80, color='green', linestyle='--', alpha=0.7, label='Target: 80%')\n",
    "# ax1.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='Acceptable: 50%')\n",
    "# ax1.legend()\n",
    "\n",
    "# RSSI vs SNR scatter\n",
    "colors = {7: 'green', 9: 'blue', 12: 'red'}\n",
    "for sf in df['sf'].unique():\n",
    "    sf_data = df[df['sf'] == sf]\n",
    "    ax2.scatter(sf_data['rssi'], sf_data['snr'], c=colors[sf], \n",
    "               label=f'SF{sf}', alpha=0.7)\n",
    "ax2.set_xlabel('RSSI (dBm)')\n",
    "ax2.set_ylabel('SNR (dB)')\n",
    "ax2.set_title('RSSI vs SNR by Spreading Factor')\n",
    "ax2.legend()\n",
    "# Format SNR axis to show integers only at integer positions\n",
    "ax2.yaxis.set_major_locator(loc(1))\n",
    "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x)}'))\n",
    "\n",
    "# RSSI distribution\n",
    "sf_values = sorted(df['sf'].unique())\n",
    "rssi_data = [df[df['sf'] == sf]['rssi'].values for sf in sf_values]\n",
    "ax3.boxplot(rssi_data, labels=[f'SF{sf}' for sf in sf_values])\n",
    "ax3.set_title('RSSI Distribution by SF')\n",
    "ax3.set_ylabel('RSSI (dBm)')\n",
    "\n",
    "# PDR vs payload size\n",
    "for sf in sf_values:\n",
    "    sf_stats = pdr_stats[pdr_stats['sf'] == sf]\n",
    "    ax4.plot(sf_stats['len'], sf_stats['pdr_percent'], \n",
    "            marker='o', linewidth=2, label=f'SF{sf}', color=colors[sf])\n",
    "ax4.set_xlabel('Payload Size (bytes)')\n",
    "ax4.set_ylabel('PDR (%)')\n",
    "ax4.set_title('PDR vs Payload Size')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Define the desired filename\n",
    "plot_filename = \"Basic_plots.png\"\n",
    "\n",
    "# Option 2: Save locally (uncomment the line below to enable)\n",
    "save_plot_locally(fig, plot_filename)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 1 - PDR Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Packet Delivery Rate with Gradient Colors\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "# Create color gradient based on PDR percentage\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Convert pandas Series to numpy array to avoid errors\n",
    "pdr_values = pdr_stats['pdr_percent'].values\n",
    "\n",
    "# Normalize PDR values for color mapping\n",
    "norm = mcolors.Normalize(vmin=pdr_values.min(), vmax=pdr_values.max())\n",
    "cmap = cm.RdYlGn  # Red-Yellow-Green colormap (red=bad, green=good)\n",
    "\n",
    "# Create bars with gradient colors\n",
    "bars = ax.bar(range(len(pdr_stats)), pdr_values, color=cmap(norm(pdr_values)))\n",
    "\n",
    "ax.set_title('Packet Delivery Rate by Configuration (Color-coded by Performance)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Configuration Index')\n",
    "ax.set_ylabel('PDR (%)')\n",
    "ax.set_xticks(range(len(pdr_stats)))\n",
    "ax.set_xticklabels([f\"SF{row['sf']}-{row['len']}B\" for _, row in pdr_stats.iterrows()], rotation=45)\n",
    "\n",
    "# Add reference lines\n",
    "# ax.axhline(y=80, color='green', linestyle='--', alpha=0.8, label='Target: 80%')\n",
    "# ax.axhline(y=50, color='orange', linestyle='--', alpha=0.8, label='Acceptable: 50%')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 1, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Add colorbar\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label('PDR (%)', rotation=270, labelpad=15)\n",
    "\n",
    "# ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 105)  # Give some space above 100%\n",
    "plt.tight_layout()\n",
    "\n",
    "# Define the desired filename\n",
    "plot_filename = \"PDR_by_Config.png\"\n",
    "\n",
    "# Option 2: Save locally (uncomment the line below to enable)\n",
    "save_plot_locally(fig, plot_filename)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best PDR: {pdr_stats['pdr_percent'].max():.1f}%\")\n",
    "print(f\"Worst PDR: {pdr_stats['pdr_percent'].min():.1f}%\")\n",
    "print(f\"Average PDR: {pdr_stats['pdr_percent'].mean():.1f}%\")\n",
    "\n",
    "# Alternative version with different colormap options\n",
    "print(\"\\nTrying different colormaps...\")\n",
    "\n",
    "# Version with Viridis colormap (purple to yellow)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "cmap_viridis = cm.viridis\n",
    "bars = ax.bar(range(len(pdr_stats)), pdr_values, color=cmap_viridis(norm(pdr_values)))\n",
    "\n",
    "ax.set_title('PDR by Configuration (Viridis Colormap)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Configuration Index')\n",
    "ax.set_ylabel('PDR (%)')\n",
    "ax.set_xticks(range(len(pdr_stats)))\n",
    "ax.set_xticklabels([f\"SF{row['sf']}-{row['len']}B\" for _, row in pdr_stats.iterrows()], rotation=45)\n",
    "\n",
    "# ax.axhline(y=80, color='white', linestyle='--', alpha=0.8, label='Target: 80%')\n",
    "# ax.axhline(y=50, color='gray', linestyle='--', alpha=0.8, label='Acceptable: 50%')\n",
    "\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 1, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "sm_viridis = cm.ScalarMappable(cmap=cmap_viridis, norm=norm)\n",
    "sm_viridis.set_array([])\n",
    "cbar = plt.colorbar(sm_viridis, ax=ax)\n",
    "cbar.set_label('PDR (%)', rotation=270, labelpad=15)\n",
    "\n",
    "# ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 105)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Version with Plasma colormap (purple to pink to yellow)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "cmap_plasma = cm.plasma\n",
    "bars = ax.bar(range(len(pdr_stats)), pdr_values, color=cmap_plasma(norm(pdr_values)))\n",
    "\n",
    "ax.set_title('PDR by Configuration (Plasma Colormap)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Configuration Index')\n",
    "ax.set_ylabel('PDR (%)')\n",
    "ax.set_xticks(range(len(pdr_stats)))\n",
    "ax.set_xticklabels([f\"SF{row['sf']}-{row['len']}B\" for _, row in pdr_stats.iterrows()], rotation=45)\n",
    "\n",
    "# ax.axhline(y=80, color='white', linestyle='--', alpha=0.8, label='Target: 80%')\n",
    "# ax.axhline(y=50, color='cyan', linestyle='--', alpha=0.8, label='Acceptable: 50%')\n",
    "\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 1, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "sm_plasma = cm.ScalarMappable(cmap=cmap_plasma, norm=norm)\n",
    "sm_plasma.set_array([])\n",
    "cbar = plt.colorbar(sm_plasma, ax=ax)\n",
    "cbar.set_label('PDR (%)', rotation=270, labelpad=15)\n",
    "\n",
    "# ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(0, 105)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packet Loss by configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate packet loss rate (inverse of PDR)\n",
    "pdr_stats['packet_loss_percent'] = 100 - pdr_stats['pdr_percent']\n",
    "\n",
    "# Plot 1: Packet Loss Rate Bar Chart\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "# Different color scheme for packet loss (red spectrum for bad performance)\n",
    "colors = ['darkred' if sf==7 else 'red' if sf==9 else 'lightcoral' for sf in pdr_stats['sf']]\n",
    "\n",
    "bars = ax.bar(range(len(pdr_stats)), pdr_stats['packet_loss_percent'], color=colors)\n",
    "\n",
    "ax.set_title('Packet Loss Rate by Configuration', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Configuration Index')\n",
    "ax.set_ylabel('Packet Loss (%)')\n",
    "ax.set_xticks(range(len(pdr_stats)))\n",
    "ax.set_xticklabels([f\"SF{row['sf']}-{row['len']}B\" for _, row in pdr_stats.iterrows()], rotation=45)\n",
    "\n",
    "# Add reference lines for packet loss (inverted thresholds)\n",
    "# ax.axhline(y=20, color='red', linestyle='--', alpha=0.7, label='Poor: >20% loss')\n",
    "# ax.axhline(y=50, color='darkred', linestyle='--', alpha=0.7, label='Critical: >50% loss')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.5, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Define the desired filename\n",
    "plot_filename = \"PL_by_Config.png\"\n",
    "\n",
    "# Option 2: Save locally (uncomment the line below to enable)\n",
    "save_plot_locally(fig, plot_filename)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best (Lowest) Packet Loss: {pdr_stats['packet_loss_percent'].min():.1f}%\")\n",
    "print(f\"Worst (Highest) Packet Loss: {pdr_stats['packet_loss_percent'].max():.1f}%\")\n",
    "\n",
    "# Alternative version with gradient colors based on loss severity\n",
    "print(\"\\nCreating gradient color version...\")\n",
    "\n",
    "# Plot 2: Packet Loss with Gradient Colors\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "\n",
    "# Create color gradient based on packet loss percentage\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Convert pandas Series to numpy array to avoid the error\n",
    "loss_values = pdr_stats['packet_loss_percent'].values\n",
    "\n",
    "# Normalize packet loss values for color mapping\n",
    "norm = mcolors.Normalize(vmin=loss_values.min(), vmax=loss_values.max())\n",
    "cmap = cm.Reds  # Red colormap for losses\n",
    "\n",
    "# Create bars with gradient colors\n",
    "bars = ax.bar(range(len(pdr_stats)), loss_values, color=cmap(norm(loss_values)))\n",
    "\n",
    "ax.set_title('Packet Loss Rate by Configuration (Color-coded by Severity)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Configuration Index')\n",
    "ax.set_ylabel('Packet Loss (%)')\n",
    "ax.set_xticks(range(len(pdr_stats)))\n",
    "ax.set_xticklabels([f\"SF{row['sf']}-{row['len']}B\" for _, row in pdr_stats.iterrows()], rotation=45)\n",
    "\n",
    "# Add reference lines\n",
    "# ax.axhline(y=20, color='orange', linestyle='--', alpha=0.8, label='Poor: >20% loss')\n",
    "# ax.axhline(y=50, color='red', linestyle='--', alpha=0.8, label='Critical: >50% loss')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.5, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Add colorbar\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax)\n",
    "cbar.set_label('Packet Loss (%)', rotation=270, labelpad=15)\n",
    "\n",
    "# ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot 3: Side-by-side comparison of PDR and Packet Loss\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Convert to numpy array and create colormap\n",
    "pdr_values = pdr_stats['pdr_percent'].values\n",
    "norm = mcolors.Normalize(vmin=pdr_values.min(), vmax=pdr_values.max())\n",
    "cmap = cm.RdYlGn  # Red-Yellow-Green colormap\n",
    "\n",
    "# Create gradient bars\n",
    "bars1 = ax1.bar(range(len(pdr_stats)), pdr_values, color=cmap(norm(pdr_values)))\n",
    "\n",
    "ax1.set_title('Packet Delivery Rate', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('PDR (%)')\n",
    "ax1.set_xticks(range(len(pdr_stats)))\n",
    "ax1.set_xticklabels([f\"SF{row['sf']}-{row['len']}B\" for _, row in pdr_stats.iterrows()], rotation=45)\n",
    "# ax1.axhline(y=80, color='green', linestyle='--', alpha=0.7, label='Target: 80%')\n",
    "# ax1.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='Acceptable: 50%')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "# ax1.legend()\n",
    "\n",
    "# Add colorbar to the subplot\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "cbar = plt.colorbar(sm, ax=ax1)\n",
    "cbar.set_label('PDR (%)', rotation=270, labelpad=15)\n",
    "\n",
    "# Add PDR value labels\n",
    "for i, bar in enumerate(bars1):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 1, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "# Packet Loss subplot\n",
    "colors_loss = ['darkred' if sf==7 else 'red' if sf==9 else 'lightcoral' for sf in pdr_stats['sf']]\n",
    "bars2 = ax2.bar(range(len(pdr_stats)), pdr_stats['packet_loss_percent'], color=colors_loss)\n",
    "ax2.set_title('Packet Loss Rate', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Packet Loss (%)')\n",
    "ax2.set_xticks(range(len(pdr_stats)))\n",
    "ax2.set_xticklabels([f\"SF{row['sf']}-{row['len']}B\" for _, row in pdr_stats.iterrows()], rotation=45)\n",
    "# ax2.axhline(y=20, color='red', linestyle='--', alpha=0.7, label='Poor: >20% loss')\n",
    "# ax2.axhline(y=50, color='darkred', linestyle='--', alpha=0.7, label='Critical: >50% loss')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "# ax2.legend()\n",
    "\n",
    "# Add loss value labels\n",
    "for i, bar in enumerate(bars2):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5, f'{height:.1f}%',\n",
    "            ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nðŸ“ˆ Performance Summary:\")\n",
    "print(f\"Best Configuration (Highest PDR): {pdr_stats.loc[pdr_stats['pdr_percent'].idxmax(), 'config_name']} - {pdr_stats['pdr_percent'].max():.1f}% PDR\")\n",
    "print(f\"Worst Configuration (Lowest PDR): {pdr_stats.loc[pdr_stats['pdr_percent'].idxmin(), 'config_name']} - {pdr_stats['pdr_percent'].min():.1f}% PDR\")\n",
    "print(f\"Average PDR across all configs: {pdr_stats['pdr_percent'].mean():.1f}%\")\n",
    "print(f\"Average Packet Loss across all configs: {pdr_stats['packet_loss_percent'].mean():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSSI vs SNR Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: RSSI vs SNR Scatter Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "\n",
    "colors = {7: 'green', 9: 'blue', 12: 'red'}\n",
    "markers = {20: 'o', 50: 's', 80: '^'}  # Different markers for payload sizes\n",
    "\n",
    "for sf in sorted(df['sf'].unique()):\n",
    "    for payload in sorted(df['len'].unique()):\n",
    "        subset = df[(df['sf'] == sf) & (df['len'] == payload)]\n",
    "        if len(subset) > 0:\n",
    "            ax.scatter(subset['rssi'], subset['snr'], \n",
    "                      c=colors[sf], marker=markers.get(payload, 'o'),\n",
    "                      label=f'SF{sf}-{payload}B', alpha=0.7, s=60)\n",
    "\n",
    "ax.set_xlabel('RSSI (dBm)', fontsize=12)\n",
    "ax.set_ylabel('SNR (dB)', fontsize=12)\n",
    "ax.set_title('RSSI vs SNR by Configuration', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "# Format SNR axis to show integers only at integer positions\n",
    "ax.yaxis.set_major_locator(loc(1))\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x)}'))\n",
    "\n",
    "# Add correlation info\n",
    "correlation = df['rssi'].corr(df['snr'])\n",
    "ax.text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "        transform=ax.transAxes, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\"))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Define the desired filename\n",
    "plot_filename = \"RSSI_SNR.png\"\n",
    "\n",
    "# Option 2: Save locally (uncomment the line below to enable)\n",
    "save_plot_locally(fig, plot_filename)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"RSSI range: {df['rssi'].min():.0f} to {df['rssi'].max():.0f} dBm\")\n",
    "print(f\"SNR range: {df['snr'].min():.0f} to {df['snr'].max():.0f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Quality Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Signal Quality Distribution\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# RSSI distribution by SF\n",
    "sf_values = sorted(df['sf'].unique())\n",
    "rssi_data = [df[df['sf'] == sf]['rssi'].values for sf in sf_values]\n",
    "box1 = ax1.boxplot(rssi_data, labels=[f'SF{sf}' for sf in sf_values], patch_artist=True)\n",
    "\n",
    "colors = ['lightgreen', 'lightblue', 'lightcoral']\n",
    "for patch, color in zip(box1['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax1.set_title('RSSI Distribution by Spreading Factor', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('RSSI (dBm)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# SNR distribution by SF\n",
    "snr_data = [df[df['sf'] == sf]['snr'].values for sf in sf_values]\n",
    "box2 = ax2.boxplot(snr_data, labels=[f'SF{sf}' for sf in sf_values], patch_artist=True)\n",
    "\n",
    "for patch, color in zip(box2['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax2.set_title('SNR Distribution by Spreading Factor', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('SNR (dB)')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "# Format SNR axis to show integers only at integer positions\n",
    "ax2.yaxis.set_major_locator(loc(1))\n",
    "ax2.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x)}'))\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "# Define the desired filename\n",
    "plot_filename = \"RSSI_SNR_vs_SF.png\"\n",
    "\n",
    "# Option 2: Save locally (uncomment the line below to enable)\n",
    "save_plot_locally(fig, plot_filename)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "for sf in sf_values:\n",
    "    sf_data = df[df['sf'] == sf]\n",
    "    print(f\"SF{sf}: RSSI={sf_data['rssi'].mean():.1f}Â±{sf_data['rssi'].std():.1f}dBm, \"\n",
    "          f\"SNR={sf_data['snr'].mean():.1f}Â±{sf_data['snr'].std():.1f}dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell: Boxplot PDR vs SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot: PDR vs Spreading Factor\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Prepare data for boxplot - group PDR values by SF\n",
    "sf_values = sorted(pdr_stats['sf'].unique())\n",
    "pdr_by_sf = []\n",
    "\n",
    "for sf in sf_values:\n",
    "    sf_data = pdr_stats[pdr_stats['sf'] == sf]['pdr_percent'].values\n",
    "    pdr_by_sf.append(sf_data)\n",
    "\n",
    "# Create boxplot\n",
    "box_plot = ax.boxplot(pdr_by_sf, labels=[f'SF{sf}' for sf in sf_values], \n",
    "                      patch_artist=True, showmeans=True)\n",
    "\n",
    "# Color the boxes\n",
    "colors = ['lightgreen', 'lightblue', 'lightcoral']\n",
    "for patch, color in zip(box_plot['boxes'], colors[:len(sf_values)]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "# Customize means markers\n",
    "for mean in box_plot['means']:\n",
    "    mean.set_marker('D')  # Diamond shape\n",
    "    mean.set_markerfacecolor('red')\n",
    "    mean.set_markeredgecolor('darkred')\n",
    "    mean.set_markersize(6)\n",
    "\n",
    "ax.set_title('ðŸ“Š PDR Distribution by Spreading Factor', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Spreading Factor', fontsize=12)\n",
    "ax.set_ylabel('Packet Delivery Rate (%)', fontsize=12)\n",
    "\n",
    "# Add reference lines\n",
    "# ax.axhline(y=80, color='green', linestyle='--', alpha=0.7, label='Target: 80%')\n",
    "# ax.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='Acceptable: 50%')\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, alpha=0.3)\n",
    "# ax.legend()\n",
    "\n",
    "\"\"\"\n",
    "# Add statistics annotations\n",
    "for i, sf in enumerate(sf_values):\n",
    "    sf_data = pdr_stats[pdr_stats['sf'] == sf]['pdr_percent']\n",
    "    mean_val = sf_data.mean()\n",
    "    std_val = sf_data.std()\n",
    "    \n",
    "    # Add text box with statistics\n",
    "    stats_text = f'Mean: {mean_val:.1f}%\\nStd: {std_val:.1f}%\\nN: {len(sf_data)}'\n",
    "    ax.text(i+1, max(sf_data) + 2, stats_text, \n",
    "            ha='center', va='bottom', fontsize=9,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "\"\"\"\n",
    "plt.tight_layout()\n",
    "\n",
    "# Define the desired filename\n",
    "plot_filename = \"PDR_by_SF_Boxplot.png\"\n",
    "\n",
    "# Option 2: Save locally (uncomment the line below to enable)\n",
    "save_plot_locally(fig, plot_filename)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"PDR Statistics by Spreading Factor:\")\n",
    "print(\"-\" * 40)\n",
    "for sf in sf_values:\n",
    "    sf_data = pdr_stats[pdr_stats['sf'] == sf]['pdr_percent']\n",
    "    print(f\"SF{sf}: Mean={sf_data.mean():.1f}%, Median={sf_data.median():.1f}%, \"\n",
    "          f\"Min={sf_data.min():.1f}%, Max={sf_data.max():.1f}%, Std={sf_data.std():.1f}%\")\n",
    "\n",
    "# Statistical significance test (if scipy available)\n",
    "try:\n",
    "    from scipy import stats\n",
    "    if len(sf_values) >= 2:\n",
    "        pdr_groups = [pdr_stats[pdr_stats['sf'] == sf]['pdr_percent'].values for sf in sf_values]\n",
    "        f_stat, p_value = stats.f_oneway(*pdr_groups)\n",
    "        print(f\"\\nðŸ”¬ ANOVA Test:\")\n",
    "        print(f\"F-statistic: {f_stat:.3f}, p-value: {p_value:.3f}\")\n",
    "        if p_value < 0.05:\n",
    "            print(\"âœ… Significant difference between SF groups (p < 0.05)\")\n",
    "        else:\n",
    "            print(\"âŒ No significant difference between SF groups (p â‰¥ 0.05)\")\n",
    "except ImportError:\n",
    "    print(\"\\nðŸ“Š Install scipy for statistical significance testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 3: Interactive Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# PLOT 3: TIME SERIES ANALYSIS (Matplotlib Version)\n",
    "# ===========================\n",
    "\n",
    "# Create figure with subplots and extra spacing\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 14))  # Increased height from 12 to 14\n",
    "fig.suptitle('ðŸ“ˆ Time Series Analysis of LoRa Link Quality', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Color map for different SF values\n",
    "colors = {7: 'green', 9: 'blue', 12: 'red'}\n",
    "\n",
    "# Get the time range from your data\n",
    "data_time_min = df['timestamp'].min()\n",
    "data_time_max = df['timestamp'].max()\n",
    "\n",
    "# Add 24-hour margins\n",
    "time_min = data_time_min - pd.Timedelta(hours=1)\n",
    "time_max = data_time_max + pd.Timedelta(hours=1)\n",
    "\n",
    "# Plot for each SF\n",
    "for sf in sorted(df['sf'].unique()):\n",
    "    sf_data = df[df['sf'] == sf]\n",
    "    \n",
    "    # Convert timestamp to datetime if it's not already\n",
    "    if not pd.api.types.is_datetime64_any_dtype(sf_data['timestamp']):\n",
    "        sf_data = sf_data.copy()\n",
    "        sf_data['timestamp'] = pd.to_datetime(sf_data['timestamp'])\n",
    "    \n",
    "    # RSSI time series (subplot 1)\n",
    "    axes[0].plot(sf_data['timestamp'], sf_data['rssi'], \n",
    "                'o-', color=colors[sf], label=f'SF{sf}', \n",
    "                markersize=4, linewidth=1, alpha=0.7)\n",
    "    \n",
    "    # SNR time series (subplot 2)\n",
    "    axes[1].plot(sf_data['timestamp'], sf_data['snr'], \n",
    "                'o-', color=colors[sf], label=f'SF{sf}', \n",
    "                markersize=4, linewidth=1, alpha=0.7)\n",
    "    \n",
    "    # Packet timeline (subplot 3) - convert to arrays to avoid type issues\n",
    "    x_vals = sf_data['timestamp'].values\n",
    "    y_vals = np.full(len(sf_data), sf)  # Create array of SF values\n",
    "    \n",
    "    axes[2].scatter(x_vals, y_vals, \n",
    "                   color=colors[sf], label=f'SF{sf}', \n",
    "                   s=40, marker='D', alpha=0.7)\n",
    "\n",
    "# Customize subplot 1 (RSSI)\n",
    "axes[0].set_title('RSSI over Time', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('RSSI (dBm)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xlim(time_min, time_max)  # Set consistent x-axis limits\n",
    "\n",
    "# Customize subplot 2 (SNR)\n",
    "axes[1].set_title('SNR over Time', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('SNR (dB)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xlim(time_min, time_max)  # Set consistent x-axis limits\n",
    "\n",
    "# Customize subplot 3 (Packet Timeline)\n",
    "axes[2].set_title('Packet Reception Timeline', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Time')\n",
    "axes[2].set_ylabel('Spreading Factor')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "axes[2].set_xlim(time_min, time_max)  # Restrict to actual data time range\n",
    "\n",
    "# Set y-axis limits for packet timeline to show SF values clearly\n",
    "sf_values = sorted(df['sf'].unique())\n",
    "axes[2].set_ylim(min(sf_values) - 0.5, max(sf_values) + 0.5)\n",
    "axes[2].set_yticks(sf_values)\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "for ax in axes:\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Add more space between subplots\n",
    "plt.subplots_adjust(hspace=0.8)  # Increase vertical spacing\n",
    "\n",
    "# Optional: Set x-axis to show hourly ticks for 12-hour dataset\n",
    "from matplotlib.dates import DateFormatter, HourLocator\n",
    "for ax in axes:\n",
    "    ax.xaxis.set_major_locator(HourLocator(interval=2))  # Show every 2 hours\n",
    "    ax.xaxis.set_major_formatter(DateFormatter('%H:%M'))  # Format as HH:MM\n",
    "\n",
    "# Define the desired filename\n",
    "plot_filename = \"Time_Series.png\"\n",
    "\n",
    "# Option 2: Save locally (uncomment the line below to enable)\n",
    "save_plot_locally(fig, plot_filename)    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDR vs Payload Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 4: PDR vs Payload Size Analysis\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "colors = {7: 'green', 9: 'blue', 12: 'red'}\n",
    "markers = ['o', 's', '^']\n",
    "\n",
    "for i, sf in enumerate(sorted(pdr_stats['sf'].unique())):\n",
    "    sf_data = pdr_stats[pdr_stats['sf'] == sf].sort_values('len')\n",
    "    ax.plot(sf_data['len'], sf_data['pdr_percent'], \n",
    "            color=colors[sf], marker=markers[i], linewidth=2, markersize=8,\n",
    "            label=f'SF{sf}')\n",
    "\n",
    "ax.set_xlabel('Payload Size (bytes)', fontsize=12)\n",
    "ax.set_ylabel('PDR (%)', fontsize=12)\n",
    "ax.set_title('ðŸ“¦ Packet Delivery Rate vs Payload Size', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Add trend annotations\n",
    "for sf in sorted(pdr_stats['sf'].unique()):\n",
    "    sf_data = pdr_stats[pdr_stats['sf'] == sf].sort_values('len')\n",
    "    if len(sf_data) > 1:\n",
    "        trend = \"â†—\" if sf_data['pdr_percent'].iloc[-1] > sf_data['pdr_percent'].iloc[0] else \"â†˜\"\n",
    "        ax.annotate(f'SF{sf} {trend}', \n",
    "                   xy=(sf_data['len'].iloc[-1], sf_data['pdr_percent'].iloc[-1]),\n",
    "                   xytext=(10, 10), textcoords='offset points',\n",
    "                   fontsize=10, color=colors[sf])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ“ˆ Payload Size Impact Analysis:\")\n",
    "for sf in sorted(pdr_stats['sf'].unique()):\n",
    "    sf_data = pdr_stats[pdr_stats['sf'] == sf]\n",
    "    print(f\"SF{sf}: PDR range {sf_data['pdr_percent'].min():.1f}% - {sf_data['pdr_percent'].max():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RSSI vs SNR Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 5: Performance Heatmaps\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# PDR Heatmap\n",
    "pdr_pivot = pdr_stats.pivot_table(values='pdr_percent', index='sf', columns='len', fill_value=0)\n",
    "im1 = ax1.imshow(pdr_pivot.values, cmap='RdYlGn', aspect='auto', vmin=0, vmax=100)\n",
    "ax1.set_title('âœ… PDR Heatmap (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(range(len(pdr_pivot.columns)))\n",
    "ax1.set_xticklabels([f'{col}B' for col in pdr_pivot.columns])\n",
    "ax1.set_yticks(range(len(pdr_pivot.index)))\n",
    "ax1.set_yticklabels([f'SF{idx}' for idx in pdr_pivot.index])\n",
    "ax1.set_xlabel('Payload Size')\n",
    "ax1.set_ylabel('Spreading Factor')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(pdr_pivot.index)):\n",
    "    for j in range(len(pdr_pivot.columns)):\n",
    "        text = ax1.text(j, i, f'{pdr_pivot.values[i, j]:.1f}%',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
    "\n",
    "plt.colorbar(im1, ax=ax1, label='PDR (%)')\n",
    "\n",
    "# RSSI Heatmap\n",
    "rssi_pivot = pdr_stats.pivot_table(values='rssi_mean', index='sf', columns='len', fill_value=0)\n",
    "im2 = ax2.imshow(rssi_pivot.values, cmap='RdYlGn_r', aspect='auto')\n",
    "ax2.set_title('ðŸ“¡ Average RSSI Heatmap', fontsize=12, fontweight='bold')\n",
    "ax2.set_xticks(range(len(rssi_pivot.columns)))\n",
    "ax2.set_xticklabels([f'{col}B' for col in rssi_pivot.columns])\n",
    "ax2.set_yticks(range(len(rssi_pivot.index)))\n",
    "ax2.set_yticklabels([f'SF{idx}' for idx in rssi_pivot.index])\n",
    "ax2.set_xlabel('Payload Size')\n",
    "ax2.set_ylabel('Spreading Factor')\n",
    "\n",
    "for i in range(len(rssi_pivot.index)):\n",
    "    for j in range(len(rssi_pivot.columns)):\n",
    "        text = ax2.text(j, i, f'{rssi_pivot.values[i, j]:.1f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"white\", fontweight='bold')\n",
    "\n",
    "plt.colorbar(im2, ax=ax2, label='RSSI (dBm)')\n",
    "\n",
    "# SNR Heatmap\n",
    "snr_pivot = pdr_stats.pivot_table(values='snr_mean', index='sf', columns='len', fill_value=0)\n",
    "im3 = ax3.imshow(snr_pivot.values, cmap='viridis', aspect='auto')\n",
    "ax3.set_title('ðŸ“¶ Average SNR Heatmap', fontsize=12, fontweight='bold')\n",
    "ax3.set_xticks(range(len(snr_pivot.columns)))\n",
    "ax3.set_xticklabels([f'{col}B' for col in snr_pivot.columns])\n",
    "ax3.set_yticks(range(len(snr_pivot.index)))\n",
    "ax3.set_yticklabels([f'SF{idx}' for idx in snr_pivot.index])\n",
    "ax3.set_xlabel('Payload Size')\n",
    "ax3.set_ylabel('Spreading Factor')\n",
    "\n",
    "for i in range(len(snr_pivot.index)):\n",
    "    for j in range(len(snr_pivot.columns)):\n",
    "        text = ax3.text(j, i, f'{snr_pivot.values[i, j]:.1f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"white\", fontweight='bold')\n",
    "\n",
    "plt.colorbar(im3, ax=ax3, label='SNR (dB)')\n",
    "\n",
    "# Packet Count Heatmap\n",
    "count_pivot = pdr_stats.pivot_table(values='packets_received', index='sf', columns='len', fill_value=0)\n",
    "im4 = ax4.imshow(count_pivot.values, cmap='Blues', aspect='auto')\n",
    "ax4.set_title('ðŸ“Š Packets Received Heatmap', fontsize=12, fontweight='bold')\n",
    "ax4.set_xticks(range(len(count_pivot.columns)))\n",
    "ax4.set_xticklabels([f'{col}B' for col in count_pivot.columns])\n",
    "ax4.set_yticks(range(len(count_pivot.index)))\n",
    "ax4.set_yticklabels([f'SF{idx}' for idx in count_pivot.index])\n",
    "ax4.set_xlabel('Payload Size')\n",
    "ax4.set_ylabel('Spreading Factor')\n",
    "\n",
    "for i in range(len(count_pivot.index)):\n",
    "    for j in range(len(count_pivot.columns)):\n",
    "        text = ax4.text(j, i, f'{int(count_pivot.values[i, j])}',\n",
    "                       ha=\"center\", va=\"center\", color=\"white\", fontweight='bold')\n",
    "\n",
    "plt.colorbar(im4, ax=ax4, label='Packet Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 4: Link Budget Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# PLOT 4: LINK BUDGET ANALYSIS (Matplotlib Version)\n",
    "# ===========================\n",
    "\n",
    "# Get unique configurations and assign colors\n",
    "configs = pdr_stats['config_name'].unique()\n",
    "colors = plt.cm.Set1(np.linspace(0, 1, len(configs)))\n",
    "color_map = {config: colors[i] for i, config in enumerate(configs)}\n",
    "\n",
    "\"\"\"\n",
    "# Create figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Link Budget Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "\n",
    "# Plot 1: PDR vs Average RSSI\n",
    "for config in configs:\n",
    "    config_data = pdr_stats[pdr_stats['config_name'] == config]\n",
    "    \n",
    "    # Use payload size (len) for bubble size, scale it appropriately\n",
    "    bubble_sizes = config_data['len'] * 3  # Scale factor for visibility\n",
    "    \n",
    "    ax1.scatter(config_data['rssi_mean'], config_data['pdr_percent'],\n",
    "               c=[color_map[config]], s=bubble_sizes, alpha=0.7,\n",
    "               label=config, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax1.set_title('PDR vs Average RSSI (bubble size = payload)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Average RSSI (dBm)')\n",
    "ax1.set_ylabel('PDR (%)')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: PDR vs Average SNR\n",
    "for config in configs:\n",
    "    config_data = pdr_stats[pdr_stats['config_name'] == config]\n",
    "    \n",
    "    # Use payload size (len) for bubble size, scale it appropriately\n",
    "    bubble_sizes = config_data['len'] * 3  # Scale factor for visibility\n",
    "    \n",
    "    ax2.scatter(config_data['snr_mean'], config_data['pdr_percent'],\n",
    "               c=[color_map[config]], s=bubble_sizes, alpha=0.7,\n",
    "               label=config, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "ax2.set_title('PDR vs Average SNR (bubble size = payload)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Average SNR (dB)')\n",
    "ax2.set_ylabel('PDR (%)')\n",
    "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# Optional: Add text annotations showing payload sizes\n",
    "print(\"Payload Size Legend:\")\n",
    "for config in configs:\n",
    "    config_data = pdr_stats[pdr_stats['config_name'] == config]\n",
    "    if len(config_data) > 0:\n",
    "        payload_size = config_data['len'].iloc[0]\n",
    "        print(f\"  {config}: {payload_size} bytes\")\n",
    "\n",
    "# Alternative version with separate plots for cleaner legends\n",
    "print(\"\\nCreating separate plots for better visibility... \\n\\n\")\n",
    "\n",
    "# Separate plot for RSSI\n",
    "plt.figure(figsize=(10, 6))\n",
    "for config in configs:\n",
    "    config_data = pdr_stats[pdr_stats['config_name'] == config]\n",
    "    bubble_sizes = config_data['len'] * 3\n",
    "    \n",
    "    plt.scatter(config_data['rssi_mean'], config_data['pdr_percent'],\n",
    "               c=[color_map[config]], s=bubble_sizes, alpha=0.7,\n",
    "               label=config, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "plt.title('PDR vs Average RSSI (bubble size = payload)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Average RSSI (dBm)')\n",
    "plt.ylabel('PDR (%)')\n",
    "plt.legend(title='Configuration', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small', labelspacing=1.4)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"\\n\" * 4) \n",
    "\n",
    "# Separate plot for SNR\n",
    "plt.figure(figsize=(10, 6))\n",
    "for config in configs:\n",
    "    config_data = pdr_stats[pdr_stats['config_name'] == config]\n",
    "    bubble_sizes = config_data['len'] * 3\n",
    "    \n",
    "    plt.scatter(config_data['snr_mean'], config_data['pdr_percent'],\n",
    "               c=[color_map[config]], s=bubble_sizes, alpha=0.7,\n",
    "               label=config, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "plt.title('PDR vs Average SNR (bubble size = payload)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Average SNR (dB)')\n",
    "plt.ylabel('PDR (%)')\n",
    "plt.legend(title='Configuration', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='small', labelspacing=1.4)\n",
    "plt.grid(True, alpha=0.3)\n",
    "#plt.subplots_adjust(hspace=0.4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# PLOT 4: LINK BUDGET ANALYSIS\n",
    "# ===========================\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# PDR vs Average RSSI\n",
    "scatter1 = ax1.scatter(pdr_stats['rssi_mean'], pdr_stats['pdr_percent'],\n",
    "           c=pdr_stats['sf'], cmap='viridis', s=pdr_stats['len']*3, alpha=0.7)\n",
    "ax1.set_xlabel('Average RSSI (dBm)')\n",
    "ax1.set_ylabel('PDR (%)')\n",
    "ax1.set_title('PDR vs RSSI (bubble size = payload)', fontsize=14, fontweight='bold')\n",
    "cbar1 = plt.colorbar(scatter1, ax=ax1, label='Spreading Factor') # Added colorbar label\n",
    "cbar1.ax.set_title('SF') # Added colorbar title\n",
    "\n",
    "\n",
    "# PDR vs Average SNR\n",
    "scatter2 = ax2.scatter(pdr_stats['snr_mean'], pdr_stats['pdr_percent'],\n",
    "           c=pdr_stats['sf'], cmap='viridis', s=pdr_stats['len']*3, alpha=0.7)\n",
    "ax2.set_xlabel('Average SNR (dB)')\n",
    "ax2.set_ylabel('PDR (%)')\n",
    "ax2.set_title('PDR vs SNR (bubble size = payload)', fontsize=14, fontweight='bold')\n",
    "cbar2 = plt.colorbar(scatter2, ax=ax2, label='Spreading Factor') # Added colorbar label\n",
    "cbar2.ax.set_title('SF') # Added colorbar title\n",
    "\n",
    "\n",
    "# Signal strength heatmap\n",
    "pivot_rssi = pdr_stats.pivot_table(values='rssi_mean', index='sf', columns='len', fill_value=0)\n",
    "sns.heatmap(pivot_rssi, annot=True, fmt='.1f', cmap='RdYlGn_r', ax=ax3, cbar_kws={'label': 'Average RSSI (dBm)'}) # Added colorbar label\n",
    "ax3.set_title('Average RSSI Heatmap', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Payload Size (bytes)')\n",
    "ax3.set_ylabel('Spreading Factor')\n",
    "\n",
    "# PDR heatmap\n",
    "pivot_pdr = pdr_stats.pivot_table(values='pdr_percent', index='sf', columns='len', fill_value=0)\n",
    "sns.heatmap(pivot_pdr, annot=True, fmt='.1f', cmap='RdYlGn', ax=ax4, cbar_kws={'label': 'PDR (%)'}) # Added colorbar label\n",
    "ax4.set_title('PDR Heatmap (%)', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('Payload Size (bytes)')\n",
    "ax4.set_ylabel('Spreading Factor')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# PLOT 4 (Part 2): LINK BUDGET ANALYSIS (Heatmaps Only)\n",
    "# ===========================\n",
    "\n",
    "fig, (ax3, ax4) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Signal strength heatmap\n",
    "pivot_rssi = pdr_stats.pivot_table(values='rssi_mean', index='sf', columns='len', fill_value=0)\n",
    "sns.heatmap(pivot_rssi, annot=True, fmt='.1f', cmap='RdYlGn_r', ax=ax3, cbar_kws={'label': 'Average RSSI (dBm)'}) # Added colorbar label\n",
    "ax3.set_title('Average RSSI Heatmap', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Payload Size (bytes)')\n",
    "ax3.set_ylabel('Spreading Factor')\n",
    "\n",
    "# PDR heatmap\n",
    "pivot_pdr = pdr_stats.pivot_table(values='pdr_percent', index='sf', columns='len', fill_value=0)\n",
    "sns.heatmap(pivot_pdr, annot=True, fmt='.1f', cmap='RdYlGn', ax=ax4, cbar_kws={'label': 'PDR (%)'}) # Added colorbar label\n",
    "ax4.set_title('PDR Heatmap (%)', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('Payload Size (bytes)')\n",
    "ax4.set_ylabel('Spreading Factor')\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6: Summary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis Summary\n",
    "print(\"ðŸ”¬ ANALYSIS RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Best/worst configurations\n",
    "best_idx = pdr_stats['pdr_percent'].idxmax()\n",
    "worst_idx = pdr_stats['pdr_percent'].idxmin()\n",
    "\n",
    "print(f\"\\nðŸ† Best Configuration:\")\n",
    "best = pdr_stats.iloc[best_idx]\n",
    "print(f\"   SF{best['sf']}, BW{best['bw']}, {best['len']}B payload\")\n",
    "print(f\"   PDR: {best['pdr_percent']}%, RSSI: {best['rssi_mean']:.1f}dBm\")\n",
    "\n",
    "print(f\"\\nâŒ Worst Configuration:\")\n",
    "worst = pdr_stats.iloc[worst_idx]\n",
    "print(f\"   SF{worst['sf']}, BW{worst['bw']}, {worst['len']}B payload\")\n",
    "print(f\"   PDR: {worst['pdr_percent']}%, RSSI: {worst['rssi_mean']:.1f}dBm\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Overall Statistics:\")\n",
    "print(f\"   Average PDR: {pdr_stats['pdr_percent'].mean():.1f}%\")\n",
    "print(f\"   RSSI range: {df['rssi'].min():.1f} to {df['rssi'].max():.1f} dBm\")\n",
    "print(f\"   SNR range: {df['snr'].min():.1f} to {df['snr'].max():.1f} dB\")\n",
    "\n",
    "print(f\"\\nâ±ï¸ Timing Recommendations:\")\n",
    "for sf in sorted(df['sf'].unique()):\n",
    "    sf_pdr = pdr_stats[pdr_stats['sf'] == sf]['pdr_percent'].mean()\n",
    "    if sf_pdr < 50:\n",
    "        rec = \"Increase interval to 15-20s\"\n",
    "    elif sf_pdr < 75:\n",
    "        rec = \"Increase interval to 10-12s\"\n",
    "    else:\n",
    "        rec = \"Current timing acceptable\"\n",
    "    print(f\"   SF{sf}: Avg PDR={sf_pdr:.1f}% â†’ {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Packet Interval Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 9. Packet Interval Analysis (Compatible with older seaborn/python)\n",
    "# ===========================\n",
    "\n",
    "df_intervals = df\n",
    "# Define a constant for the target packet interval in seconds\n",
    "TARGET_INTERVAL_SECONDS = 15 # Example: Set the expected interval between packets\n",
    "\n",
    "print(f\"\\nâ³ Analyzing Packet Intervals with Target Interval: {TARGET_INTERVAL_SECONDS} seconds\")\n",
    "\n",
    "# Calculate the difference in timestamp for consecutive packets within each configuration\n",
    "# This is crucial because interval expectations might be specific to a configuration\n",
    "# We'll group by 'config' before calculating the difference\n",
    "df['time_diff_seconds_within_config'] = df.groupby('config')['timestamp'].diff().dt.total_seconds()\n",
    "\n",
    "# The first packet within each config group will have a NaN diff, fill with 0 or the first interval if known\n",
    "# For this analysis, we're interested in the intervals *between* packets, so NaNs at the start are fine\n",
    "df['time_diff_seconds_within_config'] = df['time_diff_seconds_within_config'].fillna(0) # Fill the very first row of each group with 0\n",
    "\n",
    "print(f\"\\nCalculated packet intervals within each configuration.\")\n",
    "\n",
    "# ===========================\n",
    "# OPTION 2: Using basic matplotlib (most compatible)\n",
    "# ===========================\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Get unique configurations and create a color palette\n",
    "configs = df_intervals['config'].unique()\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(configs)))\n",
    "\n",
    "# Plot histogram for each configuration\n",
    "for i, config in enumerate(configs):\n",
    "    config_data = df_intervals[df_intervals['config'] == config]['time_diff_seconds_within_config']\n",
    "    # Remove zeros and outliers for better visualization\n",
    "    config_data = config_data[(config_data > 0) & (config_data < 50)]\n",
    "\n",
    "    if len(config_data) > 0:\n",
    "        plt.hist(config_data, bins=30, alpha=0.6, label=config, \n",
    "                color=colors[i], density=True, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "plt.axvline(TARGET_INTERVAL_SECONDS, color='red', linestyle='dashed', \n",
    "            linewidth=2, label=f'Target Interval ({TARGET_INTERVAL_SECONDS}s)')\n",
    "\n",
    "plt.title('Distribution of Packet Intervals within Configurations (matplotlib)', \n",
    "          fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Time Difference Between Packets (seconds)', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.legend(title='Configuration', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.xlim(12, 24) # Restrict x-axis to 12s-24s\n",
    "plt.ylim(0, 2)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 9. Packet Interval Analysis (Compatible with older seaborn/python)\n",
    "# ===========================\n",
    "\n",
    "# ===========================\n",
    "# OPTION 3: Separate subplots for each configuration (cleaner for many configs)\n",
    "# ===========================\n",
    "configs = df_intervals['config'].unique()\n",
    "n_configs = len(configs)\n",
    "\n",
    "# Calculate subplot grid\n",
    "n_cols = 3\n",
    "n_rows = (n_configs + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "if n_rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "elif n_cols == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "for i, config in enumerate(configs):\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    config_data = df_intervals[df_intervals['config'] == config]['time_diff_seconds_within_config']\n",
    "    # Remove zeros and outliers for better visualization\n",
    "    config_data = config_data[(config_data > 0) & (config_data < 50)]\n",
    "    \n",
    "    if len(config_data) > 0:\n",
    "        ax.hist(config_data, bins=20, alpha=0.7, color='skyblue', \n",
    "                edgecolor='black', linewidth=0.5, density=True)\n",
    "        ax.axvline(TARGET_INTERVAL_SECONDS, color='red', linestyle='dashed', \n",
    "                   linewidth=2, label=f'Target ({TARGET_INTERVAL_SECONDS}s)')\n",
    "        \n",
    "        # Add statistics text\n",
    "        mean_val = config_data.mean()\n",
    "        median_val = config_data.median()\n",
    "        ax.axvline(mean_val, color='orange', linestyle='--', alpha=0.8, label=f'Mean: {mean_val:.1f}s')\n",
    "        ax.axvline(median_val, color='green', linestyle='--', alpha=0.8, label=f'Median: {median_val:.1f}s')\n",
    "    \n",
    "    ax.set_title(f'{config}', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Interval (seconds)', fontsize=10)\n",
    "    ax.set_ylabel('Density', fontsize=10)\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.set_xlim(12, 24)\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(n_configs, n_rows * n_cols):\n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    axes[row, col].set_visible(False)\n",
    "\n",
    "plt.suptitle('Packet Interval Distributions by Configuration', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“ˆ Interval Analysis per Configuration:\")\n",
    "interval_stats = df_intervals.groupby('config')['time_diff_seconds_within_config'].agg(['mean', 'median', 'std', 'min', 'max', 'count']).round(2)\n",
    "interval_stats['target_interval'] = TARGET_INTERVAL_SECONDS\n",
    "interval_stats['deviation_from_target (mean)'] = (interval_stats['mean'] - TARGET_INTERVAL_SECONDS).round(2)\n",
    "interval_stats['deviation_from_target (median)'] = (interval_stats['median'] - TARGET_INTERVAL_SECONDS).round(2)\n",
    "\n",
    "# Shorten specific column names\n",
    "new_column_names = {\n",
    "    'target_interval': 'target',\n",
    "    'deviation_from_target (mean)': 'dev_mean',\n",
    "    'deviation_from_target (median)': 'dev_median'\n",
    "}\n",
    "interval_stats = interval_stats.rename(columns=new_column_names)\n",
    "\n",
    "# Use print instead of display for compatibility\n",
    "print(\"\\nInterval Statistics:\")\n",
    "print(interval_stats.to_string())\n",
    "\n",
    "# Create a simple box plot for interval comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Prepare data for box plot\n",
    "configs = df_intervals['config'].unique()\n",
    "interval_data = []\n",
    "config_labels = []\n",
    "\n",
    "for config in configs:\n",
    "    config_data = df_intervals[df_intervals['config'] == config]['time_diff_seconds_within_config']\n",
    "    # Remove zeros and outliers\n",
    "    config_data = config_data[(config_data > 0) & (config_data < 50)]\n",
    "    if len(config_data) > 0:\n",
    "        interval_data.append(config_data.values)\n",
    "        config_labels.append(config)\n",
    "\n",
    "# Create box plot\n",
    "plt.boxplot(interval_data, labels=config_labels)\n",
    "plt.axhline(TARGET_INTERVAL_SECONDS, color='red', linestyle='dashed', \n",
    "           linewidth=2, label=f'Target Interval ({TARGET_INTERVAL_SECONDS}s)')\n",
    "plt.title('Packet Interval Distribution by Configuration (Box Plot)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Configuration', fontsize=12)\n",
    "plt.ylabel('Interval (seconds)', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretation Suggestions:\n",
    "print(\"\\nðŸ§  Interpretation of Packet Interval Analysis:\")\n",
    "print(f\"\\n- Average/Median Interval (mean, median columns): Compare these to the TARGET_INTERVAL_SECONDS ({TARGET_INTERVAL_SECONDS}s). Values significantly higher might indicate delays, network congestion, or issues with the transmitting node's timing. Values lower might suggest bursts or inaccurate timing.\")\n",
    "print(f\"\\n- Standard Deviation (std column): A high standard deviation indicates significant variability in packet arrival times. This can impact applications sensitive to consistent timing, like real-time monitoring.\")\n",
    "print(f\"\\n- Minimum/Maximum Interval (min, max columns): Extreme values can highlight anomalies. Very small 'min' values might be duplicates or rapid bursts. Very large 'max' values show significant gaps in reception.\")\n",
    "print(f\"\\n- Deviation from Target: Positive values mean the average/median interval is longer than expected. Negative values mean it's shorter.\")\n",
    "print(f\"\\n- Compare Configurations: Look for how different configurations (SF, BW, Payload) affect the interval statistics. Do higher SFs or larger payloads lead to longer or more variable intervals? (Requires more controlled experiments or analysis on cycle data).\")\n",
    "print(f\"\\n- Correlation with Signal Quality/PDR: Are configurations with worse PDR or signal quality also showing larger or more variable intervals? This could indicate that poor link quality leads to retransmissions (if implemented) or missed packets, affecting the observed interval.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9b. Alternative Packet Interval Visualization (Box Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 9b. Alternative Packet Interval Visualization (Box Plot)\n",
    "# ===========================\n",
    "\n",
    "# Use a box plot to visualize the distribution of packet intervals for each configuration\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(data=df_intervals, x='config', y='time_diff_seconds_within_config', palette='viridis')\n",
    "\n",
    "plt.axhline(TARGET_INTERVAL_SECONDS, color='red', linestyle='dashed', linewidth=1, label=f'Target Interval ({TARGET_INTERVAL_SECONDS}s)')\n",
    "\n",
    "plt.title('Distribution of Packet Intervals per Configuration (Box Plot)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Configuration', fontsize=12)\n",
    "plt.ylabel('Time Difference Between Packets (seconds)', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right') # Rotate labels for readability\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "plt.ylim(13, 22) # Restrict y-axis to 13s-22s\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ§  Box Plot Interpretation:\")\n",
    "print(\"- The box represents the interquartile range (IQR), containing the middle 50% of the data.\")\n",
    "print(\"- The line inside the box is the median packet interval.\")\n",
    "print(\"- The 'whiskers' extend to show the range of the data, excluding outliers.\")\n",
    "print(\"- Points beyond the whiskers are considered outliers.\")\n",
    "print(\"- Compare the boxes and medians for each configuration to see which ones have longer/shorter typical intervals and more variability (wider boxes and longer whiskers).\")\n",
    "print(\"- Compare the boxes/medians to the red dashed line (Target Interval) to see how configurations perform relative to expectation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9d. Cumulative Packet Interval Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 9d. Cumulative Packet Interval Histogram\n",
    "# ===========================\n",
    "\n",
    "# Ensure the 'time_diff_seconds_within_config' column is calculated if not already\n",
    "if 'time_diff_seconds_within_config' not in df.columns:\n",
    "    print(\"Calculating packet intervals within configurations...\")\n",
    "    df['time_diff_seconds_within_config'] = df.groupby('config')['timestamp'].diff().dt.total_seconds()\n",
    "    df['time_diff_seconds_within_config'] = df['time_diff_seconds_within_config'].fillna(0)\n",
    "\n",
    "# Filter out the first entry of each group as it's the start of a new sequence\n",
    "df_intervals_for_hist = df[df['time_diff_seconds_within_config'] > 0].copy()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Iterate through each unique configuration and plot its cumulative distribution\n",
    "unique_configs = sorted(df_intervals_for_hist['config'].unique())\n",
    "colors = plt.cm.tab20.colors # Use a color map with enough distinct colors\n",
    "\n",
    "for i, config in enumerate(unique_configs):\n",
    "    config_data = df_intervals_for_hist[df_intervals_for_hist['config'] == config]['time_diff_seconds_within_config'].sort_values()\n",
    "    cumulative_counts = np.arange(1, len(config_data) + 1)\n",
    "    plt.plot(config_data, cumulative_counts, label=config, color=colors[i % len(colors)]) # Use modulo for color cycling\n",
    "\n",
    "plt.axvline(TARGET_INTERVAL_SECONDS, color='red', linestyle='dashed', linewidth=1, label=f'Target Interval ({TARGET_INTERVAL_SECONDS}s)')\n",
    "\n",
    "plt.title('Cumulative Distribution of Packet Intervals per Configuration', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Time Difference Between Packets (seconds)', fontsize=12)\n",
    "plt.ylabel('Cumulative Count of Packets', fontsize=12)\n",
    "plt.legend(title='Configuration', bbox_to_anchor=(1.05, 1), loc='upper left') # Add legend outside the plot\n",
    "plt.grid(axis='y', alpha=0.5)\n",
    "#plt.xlim(12, 24) # Restrict x-axis to 12s-24s\n",
    "#plt.tight_layout() # Adjust layout to make room for the legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: RSSI CDF by Spreading Factor\n",
    "# ===========================\n",
    "# CDF 1: RSSI Distribution\n",
    "# ===========================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Colors for different SF values\n",
    "colors = {7: 'green', 9: 'blue', 12: 'red'}\n",
    "\n",
    "# Plot CDF for each SF\n",
    "for sf in sorted(df['sf'].unique()):\n",
    "    sf_data = df[df['sf'] == sf]['rssi'].values\n",
    "    \n",
    "    # Sort the data\n",
    "    sorted_data = np.sort(sf_data)\n",
    "    \n",
    "    # Calculate CDF (cumulative probabilities)\n",
    "    n = len(sorted_data)\n",
    "    y_values = np.arange(1, n + 1) / n\n",
    "    \n",
    "    # Plot CDF\n",
    "    ax.plot(sorted_data, y_values, color=colors[sf], linewidth=2, \n",
    "            label=f'SF{sf} (n={n})', alpha=0.8)\n",
    "    \n",
    "    # Add some statistics as vertical lines\n",
    "    mean_rssi = np.mean(sf_data)\n",
    "    ax.axvline(mean_rssi, color=colors[sf], linestyle='--', alpha=0.5)\n",
    "\n",
    "ax.set_title('ðŸ“¶ RSSI Cumulative Distribution Function by Spreading Factor', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('RSSI (dBm)')\n",
    "ax.set_ylabel('P(RSSI â‰¤ x)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add interpretation text\n",
    "ax.text(0.02, 0.78, 'Interpretation:\\nâ€¢ Steeper curve = less variability\\nâ€¢ Right-shifted = better signal strength', \n",
    "        transform=ax.transAxes, verticalalignment='top', fontsize=9,\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key percentiles\n",
    "print(\"RSSI Percentiles by SF:\")\n",
    "for sf in sorted(df['sf'].unique()):\n",
    "    sf_rssi = df[df['sf'] == sf]['rssi']\n",
    "    print(f\"SF{sf}: 10th={sf_rssi.quantile(0.1):.1f}, 50th={sf_rssi.quantile(0.5):.1f}, 90th={sf_rssi.quantile(0.9):.1f} dBm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: SNR CDF by Spreading Factor\n",
    "# ===========================\n",
    "# CDF 2: SNR Distribution\n",
    "# ===========================\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Plot CDF for each SF\n",
    "for sf in sorted(df['sf'].unique()):\n",
    "    sf_data = df[df['sf'] == sf]['snr'].values\n",
    "    \n",
    "    # Sort the data\n",
    "    sorted_data = np.sort(sf_data)\n",
    "    \n",
    "    # Calculate CDF\n",
    "    n = len(sorted_data)\n",
    "    y_values = np.arange(1, n + 1) / n\n",
    "    \n",
    "    # Plot CDF\n",
    "    ax.plot(sorted_data, y_values, color=colors[sf], linewidth=2, \n",
    "            label=f'SF{sf} (n={n})', alpha=0.8)\n",
    "    \n",
    "    # Add mean as vertical line\n",
    "    mean_snr = np.mean(sf_data)\n",
    "    ax.axvline(mean_snr, color=colors[sf], linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add reference lines for SNR thresholds\n",
    "ax.axvline(0, color='red', linestyle=':', alpha=0.7, label='SNR = 0 dB')\n",
    "ax.axvline(-10, color='orange', linestyle=':', alpha=0.7, label='SNR = -10 dB')\n",
    "\n",
    "ax.set_title('ðŸ“Š SNR Cumulative Distribution Function by Spreading Factor', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('SNR (dB)')\n",
    "ax.set_ylabel('P(SNR â‰¤ x)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(left=0)\n",
    "# Format SNR axis to show integers only\n",
    "ax.xaxis.set_major_locator(loc(1))\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x)}'))\n",
    "\n",
    "\n",
    "# Add interpretation\n",
    "ax.text(0.02, 0.14, 'Interpretation:\\nâ€¢ Higher SNR = better demodulation\\nâ€¢ Left tail shows worst-case conditions', \n",
    "        transform=ax.transAxes, verticalalignment='top', fontsize=9,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print SNR percentiles\n",
    "print(\"SNR Percentiles by SF:\")\n",
    "for sf in sorted(df['sf'].unique()):\n",
    "    sf_snr = df[df['sf'] == sf]['snr']\n",
    "    print(f\"SF{sf}: 10th={sf_snr.quantile(0.1):.0f}, 50th={sf_snr.quantile(0.5):.0f}, 90th={sf_snr.quantile(0.9):.0f} dB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: PDR CDF by Configuration\n",
    "# ===========================\n",
    "# CDF 3: PDR Distribution \n",
    "# ===========================\n",
    "\n",
    "# First calculate PDR using your existing function (assuming pdr_stats exists)\n",
    "# If pdr_stats doesn't exist, uncomment and run your PDR calculation\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Plot CDF for PDR values\n",
    "pdr_values = pdr_stats['pdr_percent'].values\n",
    "sorted_pdr = np.sort(pdr_values)\n",
    "n = len(sorted_pdr)\n",
    "y_values = np.arange(1, n + 1) / n\n",
    "\n",
    "ax.plot(sorted_pdr, y_values, color='purple', linewidth=3, \n",
    "        label=f'All Configurations (n={n})', alpha=0.8)\n",
    "\n",
    "# Add reference lines for performance thresholds\n",
    "ax.axvline(80, color='green', linestyle='--', alpha=0.7, label='Target: 80% PDR')\n",
    "ax.axvline(50, color='orange', linestyle='--', alpha=0.7, label='Acceptable: 50% PDR')\n",
    "ax.axvline(np.median(pdr_values), color='red', linestyle=':', alpha=0.7, label=f'Median: {np.median(pdr_values):.1f}%')\n",
    "\n",
    "ax.set_title('ðŸ“ˆ PDR Cumulative Distribution Function Across All Configurations', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Packet Delivery Rate (%)')\n",
    "ax.set_ylabel('P(PDR â‰¤ x)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "# Add interpretation\n",
    "ax.text(0.02, 0.14, 'Interpretation:\\nâ€¢ Steep rise = consistent performance\\nâ€¢ Flat areas = performance gaps', \n",
    "        transform=ax.transAxes, verticalalignment='top', fontsize=9,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print PDR statistics\n",
    "pdr_below_50 = (pdr_values <= 50).mean() * 100\n",
    "pdr_above_80 = (pdr_values >= 80).mean() * 100\n",
    "print(f\"PDR Analysis:\")\n",
    "print(f\"â€¢ {pdr_below_50:.1f}% of configurations have PDR â‰¤ 50%\")\n",
    "print(f\"â€¢ {pdr_above_80:.1f}% of configurations have PDR â‰¥ 80%\")\n",
    "print(f\"â€¢ Median PDR: {np.median(pdr_values):.1f}%\")\n",
    "\n",
    "#=============================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Packet Loss CDF by Configuration  \n",
    "# ===========================\n",
    "# CDF 4: Packet Loss Distribution\n",
    "# ===========================\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Calculate packet loss from PDR\n",
    "packet_loss_values = 100 - pdr_stats['pdr_percent'].values\n",
    "sorted_loss = np.sort(packet_loss_values)\n",
    "n = len(sorted_loss)\n",
    "y_values = np.arange(1, n + 1) / n\n",
    "\n",
    "ax.plot(sorted_loss, y_values, color='red', linewidth=3, \n",
    "        label=f'All Configurations (n={n})', alpha=0.8)\n",
    "\n",
    "# Add reference lines for loss thresholds\n",
    "ax.axvline(20, color='orange', linestyle='--', alpha=0.7, label='Poor: 20% loss')\n",
    "ax.axvline(50, color='red', linestyle='--', alpha=0.7, label='Critical: 50% loss')\n",
    "ax.axvline(np.median(packet_loss_values), color='blue', linestyle=':', alpha=0.7, \n",
    "           label=f'Median: {np.median(packet_loss_values):.1f}%')\n",
    "\n",
    "ax.set_title('ðŸ“‰ Packet Loss Cumulative Distribution Function', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Packet Loss (%)')\n",
    "ax.set_ylabel('P(Loss â‰¤ x)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "# Add interpretation\n",
    "ax.text(0.98, 0.02, 'Interpretation:\\nâ€¢ Lower is better\\nâ€¢ Steep rise at low values = reliable system', \n",
    "        transform=ax.transAxes, verticalalignment='bottom', horizontalalignment='right', fontsize=9,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print loss statistics\n",
    "loss_above_20 = (packet_loss_values >= 20).mean() * 100\n",
    "loss_above_50 = (packet_loss_values >= 50).mean() * 100\n",
    "print(f\"Packet Loss Analysis:\")\n",
    "print(f\"â€¢ {loss_above_20:.1f}% of configurations have loss â‰¥ 20%\")\n",
    "print(f\"â€¢ {loss_above_50:.1f}% of configurations have loss â‰¥ 50%\")\n",
    "print(f\"â€¢ Median loss: {np.median(packet_loss_values):.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Packet Interval CDF by Configuration\n",
    "# ===========================\n",
    "# CDF 5: Packet Interval Distribution\n",
    "# ===========================\n",
    "\n",
    "# Calculate packet intervals (assuming you have the time difference calculation)\n",
    "# This assumes you've calculated packet intervals as shown in your earlier code\n",
    "df_sorted = df.sort_values(['config', 'timestamp'])\n",
    "df_sorted['time_diff_seconds'] = df_sorted.groupby('config')['timestamp'].diff().dt.total_seconds()\n",
    "\n",
    "# Remove NaN values and outliers\n",
    "intervals = df_sorted['time_diff_seconds'].dropna()\n",
    "intervals = intervals[(intervals > 0) & (intervals < 60)]  # Remove outliers > 60 seconds\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Plot overall interval CDF\n",
    "sorted_intervals = np.sort(intervals.values)\n",
    "n = len(sorted_intervals)\n",
    "y_values = np.arange(1, n + 1) / n\n",
    "\n",
    "ax.plot(sorted_intervals, y_values, color='navy', linewidth=3, \n",
    "        label=f'All Packets (n={n})', alpha=0.8)\n",
    "\n",
    "# Add reference lines\n",
    "target_interval = 15  # Your target interval\n",
    "ax.axvline(target_interval, color='green', linestyle='--', alpha=0.7, \n",
    "           label=f'Target: {target_interval}s')\n",
    "ax.axvline(np.median(intervals), color='red', linestyle=':', alpha=0.7, \n",
    "           label=f'Median: {np.median(intervals):.1f}s')\n",
    "\n",
    "ax.set_title('â±ï¸ Packet Interval Cumulative Distribution Function', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Packet Interval (seconds)')\n",
    "ax.set_ylabel('P(Interval â‰¤ x)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add interpretation\n",
    "ax.text(0.98, 0.02, 'Interpretation:\\nâ€¢ Tight around target = consistent timing\\nâ€¢ Long tail = delayed packets', \n",
    "        transform=ax.transAxes, verticalalignment='bottom', horizontalalignment='right', fontsize=9,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print interval statistics\n",
    "intervals_on_time = ((intervals >= target_interval - 2) & (intervals <= target_interval + 2)).mean() * 100\n",
    "print(f\"Packet Interval Analysis:\")\n",
    "print(f\"â€¢ {intervals_on_time:.1f}% of packets arrived within Â±2s of target ({target_interval}s)\")\n",
    "print(f\"â€¢ Median interval: {np.median(intervals):.1f}s\")\n",
    "print(f\"â€¢ 90th percentile: {np.quantile(intervals, 0.9):.1f}s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Combined Signal Quality CDF (RSSI + SNR)\n",
    "# ===========================\n",
    "# CDF 6: Combined Signal Quality Analysis\n",
    "# ===========================\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 15))\n",
    "\n",
    "# RSSI CDF by payload size (if available)\n",
    "if 'payload_size' in df.columns:\n",
    "    payload_sizes = sorted(df['payload_size'].unique())\n",
    "    payload_colors = plt.cm.Set1(np.linspace(0, 1, len(payload_sizes)))\n",
    "    \n",
    "    for i, payload in enumerate(payload_sizes):\n",
    "        payload_data = df[df['payload_size'] == payload]['rssi'].values\n",
    "        sorted_data = np.sort(payload_data)\n",
    "        n = len(sorted_data)\n",
    "        y_values = np.arange(1, n + 1) / n\n",
    "        \n",
    "        ax1.plot(sorted_data, y_values, color=payload_colors[i], linewidth=2, \n",
    "                label=f'{payload}B payload (n={n})', alpha=0.8)\n",
    "else:\n",
    "    # Fallback: extract from config if payload_size column doesn't exist\n",
    "    payload_configs = df['config'].str.extract(r'(\\d+)B').astype(int).iloc[:, 0].unique()\n",
    "    payload_colors = plt.cm.Set1(np.linspace(0, 1, len(payload_configs)))\n",
    "    \n",
    "    for i, payload in enumerate(sorted(payload_configs)):\n",
    "        payload_data = df[df['config'].str.contains(f'{payload}B')]['rssi'].values\n",
    "        sorted_data = np.sort(payload_data)\n",
    "        n = len(sorted_data)\n",
    "        y_values = np.arange(1, n + 1) / n\n",
    "        \n",
    "        ax1.plot(sorted_data, y_values, color=payload_colors[i], linewidth=2, \n",
    "                label=f'{payload}B payload (n={n})', alpha=0.8)\n",
    "\n",
    "ax1.set_title('RSSI CDF by Payload Size', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('RSSI (dBm)')\n",
    "ax1.set_ylabel('P(RSSI â‰¤ x)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# SNR CDF by payload size\n",
    "if 'payload_size' in df.columns:\n",
    "    for i, payload in enumerate(payload_sizes):\n",
    "        payload_data = df[df['payload_size'] == payload]['snr'].values\n",
    "        sorted_data = np.sort(payload_data)\n",
    "        n = len(sorted_data)\n",
    "        y_values = np.arange(1, n + 1) / n\n",
    "        \n",
    "        ax2.plot(sorted_data, y_values, color=payload_colors[i], linewidth=2, \n",
    "                label=f'{payload}B payload (n={n})', alpha=0.8)\n",
    "else:\n",
    "    for i, payload in enumerate(sorted(payload_configs)):\n",
    "        payload_data = df[df['config'].str.contains(f'{payload}B')]['snr'].values\n",
    "        sorted_data = np.sort(payload_data)\n",
    "        n = len(sorted_data)\n",
    "        y_values = np.arange(1, n + 1) / n\n",
    "        \n",
    "        ax2.plot(sorted_data, y_values, color=payload_colors[i], linewidth=2, \n",
    "                label=f'{payload}B payload (n={n})', alpha=0.8)\n",
    "\n",
    "ax2.set_title('SNR CDF by Payload Size', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('SNR (dB)')\n",
    "ax2.set_ylabel('P(SNR â‰¤ x)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "# Format RSSI axis to show integers only (optional)\n",
    "ax2.xaxis.set_major_locator(loc(1))\n",
    "ax2.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x)}'))\n",
    "\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.show()\n",
    "\n",
    "print(\"Combined Analysis: Signal quality distributions show how payload size affects link performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# PLOT 7: TEMPERATURE OVER TIME\n",
    "# ===========================\n",
    "\n",
    "import json\n",
    "\n",
    "# Extract temperature from the 'data' column\n",
    "def extract_temperature(data_string):\n",
    "    try:\n",
    "        data_dict = json.loads(data_string)\n",
    "        return data_dict.get(\"TC\") # Assuming 'TC' is the temperature key\n",
    "    except:\n",
    "        return None # Return None if parsing fails\n",
    "\n",
    "df['temperature'] = df['data'].apply(extract_temperature)\n",
    "\n",
    "# Plot temperature over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=df, x='timestamp', y='temperature', hue='sf_category')\n",
    "plt.title('Temperature over Time by Spreading Factor', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Temperature (Â°C)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Spreading Factor Category') # Added legend title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics against Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Direct conversion of the original plotly code to matplotlib\n",
    "def plot_bw_specific_data(df, bw_value):\n",
    "    \"\"\"\n",
    "    Plots RSSI, SNR, and Packet delivery rate over time for a specific BW using matplotlib.\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing the data.\n",
    "        bw_value (int): The BW value to filter the data (e.g., 125 or 500).\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“Š Plotting data for BW{bw_value}...\")\n",
    "    \n",
    "    # Filter data for the specific BW\n",
    "    df_bw = df[df['bw'] == bw_value].copy()\n",
    "    if df_bw.empty:\n",
    "        print(f\"âŒ No data found for BW{bw_value}.\")\n",
    "        return\n",
    "    \n",
    "    # Ensure timestamp is sorted for time series plots\n",
    "    df_bw = df_bw.sort_values('timestamp')\n",
    "    \n",
    "    # Calculate time range with 1-hour margins\n",
    "    time_min_data = df_bw['timestamp'].min()\n",
    "    time_max_data = df_bw['timestamp'].max()\n",
    "    time_min = time_min_data - pd.Timedelta(hours=1)\n",
    "    time_max = time_max_data + pd.Timedelta(hours=1)\n",
    "    \n",
    "    # Get unique configurations and colors\n",
    "    configs = df_bw['config'].unique()\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(configs)))\n",
    "    color_map = {config: colors[i] for i, config in enumerate(configs)}\n",
    "    \n",
    "    # Plotting RSSI over time\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for config in configs:\n",
    "        config_data = df_bw[df_bw['config'] == config]\n",
    "        plt.plot(config_data['timestamp'], config_data['rssi'], \n",
    "                'o-', color=color_map[config], label=config, markersize=4, linewidth=1)\n",
    "    \n",
    "    plt.title(f'RSSI over Time for BW{bw_value}', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('RSSI (dBm)')\n",
    "    plt.xlim(time_min, time_max)  # Restrict x-axis\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting SNR over time\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for config in configs:\n",
    "        config_data = df_bw[df_bw['config'] == config]\n",
    "        plt.plot(config_data['timestamp'], config_data['snr'], \n",
    "                'o-', color=color_map[config], label=config, markersize=4, linewidth=1)\n",
    "    \n",
    "    plt.title(f'SNR over Time for BW{bw_value}', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('SNR (dB)')\n",
    "    plt.xlim(time_min, time_max)  # Restrict x-axis\n",
    "    # Format SNR y-axis to show integers only\n",
    "    plt.gca().yaxis.set_major_locator(loc(1))\n",
    "    plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x)}'))\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plotting Packet Reception Timeline\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Get unique configs and SF values\n",
    "    # configs_ordered = sorted(df_bw['config'].unique())\n",
    "    # Get unique configs and SF values - sort by SF then by config\n",
    "    configs_ordered = []\n",
    "    for sf in sorted(df_bw['sf'].unique()):  # This ensures SF order: 7, 9, 12\n",
    "        sf_configs = df_bw[df_bw['sf'] == sf]['config'].unique()\n",
    "        configs_ordered.extend(sorted(sf_configs))\n",
    "    sf_values = sorted(df_bw['sf'].unique())\n",
    "    sf_colors = plt.cm.viridis(np.linspace(0, 1, len(sf_values)))\n",
    "    sf_color_map = {sf: sf_colors[i] for i, sf in enumerate(sf_values)}\n",
    "    \n",
    "    # Create y-axis mapping\n",
    "    y_positions = {config: i for i, config in enumerate(configs_ordered)}\n",
    "    \n",
    "    # Plot points for each SF\n",
    "    for sf in sf_values:\n",
    "        sf_data = df_bw[df_bw['sf'] == sf]\n",
    "        x_vals = sf_data['timestamp'].values\n",
    "        y_vals = [y_positions[config] for config in sf_data['config'].values]\n",
    "        \n",
    "        plt.scatter(x_vals, y_vals, color=sf_color_map[sf], \n",
    "                   alpha=0.7, s=30, label=f'SF{sf}')\n",
    "    \n",
    "    plt.title(f'Packet Reception Timeline for BW{bw_value}', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Configuration (SF_BW_Payload)')\n",
    "    plt.xlim(time_min, time_max)  # Restrict x-axis to data range + 1 hour margins\n",
    "    plt.yticks(range(len(configs_ordered)), configs_ordered)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot for BW125\n",
    "plot_bw_specific_data(df, 125)\n",
    "# Plot for BW500\n",
    "plot_bw_specific_data(df, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# PDR OVER TIME BY BANDWIDTH\n",
    "# ===========================\n",
    "\n",
    "def calculate_rolling_pdr(df, time_window_hours=2):\n",
    "    \"\"\"\n",
    "    Calculate PDR over rolling time windows\n",
    "    \"\"\"\n",
    "    # Sort by timestamp\n",
    "    df_sorted = df.sort_values('timestamp')\n",
    "    \n",
    "    # Create time bins\n",
    "    time_min = df_sorted['timestamp'].min()\n",
    "    time_max = df_sorted['timestamp'].max()\n",
    "    time_range = pd.date_range(start=time_min, end=time_max, freq=f'{time_window_hours}H')\n",
    "    \n",
    "    pdr_results = []\n",
    "    \n",
    "    for i in range(len(time_range) - 1):\n",
    "        window_start = time_range[i]\n",
    "        window_end = time_range[i + 1]\n",
    "        window_center = window_start + (window_end - window_start) / 2\n",
    "        \n",
    "        # Filter data for this time window\n",
    "        window_data = df_sorted[\n",
    "            (df_sorted['timestamp'] >= window_start) & \n",
    "            (df_sorted['timestamp'] < window_end)\n",
    "        ]\n",
    "        \n",
    "        if len(window_data) > 0:\n",
    "            # Calculate PDR for each SF in this window\n",
    "            for sf in window_data['sf'].unique():\n",
    "                sf_data = window_data[window_data['sf'] == sf]\n",
    "                packets_received = len(sf_data)\n",
    "                expected_packets = 200  # Your expected packets per config\n",
    "                pdr = (packets_received / expected_packets * 100)\n",
    "                \n",
    "                pdr_results.append({\n",
    "                    'timestamp': window_center,\n",
    "                    'sf': sf,\n",
    "                    'packets_received': packets_received,\n",
    "                    'pdr_percent': pdr\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(pdr_results)\n",
    "\n",
    "# Calculate PDR over time for each BW\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12))\n",
    "fig.suptitle('ðŸ“Š Packet Delivery Rate over Time by Bandwidth', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Set time limits with 1-hour margins\n",
    "data_time_min = df['timestamp'].min()\n",
    "data_time_max = df['timestamp'].max()\n",
    "time_min = data_time_min - pd.Timedelta(hours=1)\n",
    "time_max = data_time_max + pd.Timedelta(hours=1)\n",
    "\n",
    "# Colors for different SF\n",
    "colors = {7: 'green', 9: 'blue', 12: 'red'}\n",
    "\n",
    "# Extract BW values from config or use your method\n",
    "# Assuming BW is in the config string like \"SF7_BW125_20B\"\n",
    "df['bw_extracted'] = df['config'].str.extract(r'BW(\\d+)').astype(int)\n",
    "\n",
    "# Plot 1: BW125\n",
    "ax1.set_title('BW125 - PDR over Time', fontsize=14, fontweight='bold')\n",
    "bw_125_data = df[df['bw_extracted'] == 125]\n",
    "\n",
    "if not bw_125_data.empty:\n",
    "    pdr_125 = calculate_rolling_pdr(bw_125_data, time_window_hours=2)\n",
    "    \n",
    "    for sf in sorted(pdr_125['sf'].unique()):\n",
    "        sf_pdr = pdr_125[pdr_125['sf'] == sf]\n",
    "        ax1.plot(sf_pdr['timestamp'], sf_pdr['pdr_percent'], \n",
    "                'o-', color=colors[sf], label=f'SF{sf}', \n",
    "                markersize=6, linewidth=2, alpha=0.8)\n",
    "\n",
    "ax1.set_ylabel('PDR (%)')\n",
    "ax1.set_xlim(time_min, time_max)\n",
    "ax1.axhline(y=80, color='green', linestyle='--', alpha=0.7, label='Target: 80%')\n",
    "ax1.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='Acceptable: 50%')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 105)\n",
    "\n",
    "# Plot 2: BW500\n",
    "ax2.set_title('BW500 - PDR over Time', fontsize=14, fontweight='bold')\n",
    "bw_500_data = df[df['bw_extracted'] == 500]\n",
    "\n",
    "if not bw_500_data.empty:\n",
    "    pdr_500 = calculate_rolling_pdr(bw_500_data, time_window_hours=2)\n",
    "    \n",
    "    for sf in sorted(pdr_500['sf'].unique()):\n",
    "        sf_pdr = pdr_500[pdr_500['sf'] == sf]\n",
    "        ax2.plot(sf_pdr['timestamp'], sf_pdr['pdr_percent'], \n",
    "                'o-', color=colors[sf], label=f'SF{sf}', \n",
    "                markersize=6, linewidth=2, alpha=0.8)\n",
    "\n",
    "ax2.set_xlabel('Time')\n",
    "ax2.set_ylabel('PDR (%)')\n",
    "ax2.set_xlim(time_min, time_max)\n",
    "ax2.axhline(y=80, color='green', linestyle='--', alpha=0.7, label='Target: 80%')\n",
    "ax2.axhline(y=50, color='orange', linestyle='--', alpha=0.7, label='Acceptable: 50%')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 105)\n",
    "\n",
    "# Format x-axis\n",
    "from matplotlib.dates import DateFormatter, HourLocator\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.xaxis.set_major_locator(HourLocator(interval=2))\n",
    "    ax.xaxis.set_major_formatter(DateFormatter('%H:%M'))\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "# plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nðŸ“ˆ PDR Over Time Summary:\")\n",
    "if not bw_125_data.empty:\n",
    "    print(f\"BW125 - Average PDR by SF:\")\n",
    "    pdr_125_summary = pdr_125.groupby('sf')['pdr_percent'].mean()\n",
    "    for sf, avg_pdr in pdr_125_summary.items():\n",
    "        print(f\"  SF{sf}: {avg_pdr:.1f}%\")\n",
    "\n",
    "if not bw_500_data.empty:\n",
    "    print(f\"BW500 - Average PDR by SF:\")\n",
    "    pdr_500_summary = pdr_500.groupby('sf')['pdr_percent'].mean()\n",
    "    for sf, avg_pdr in pdr_500_summary.items():\n",
    "        print(f\"  SF{sf}: {avg_pdr:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
